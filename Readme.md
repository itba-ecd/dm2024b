<h1 align="center"> ğŸ“š Mineria de datos ITBA Cohorte B 2024 ğŸ“š </h1>
En este repositorio podemos observar distintos scripts en los que fuimos implementando distintos modelos predictivos y a su vez aprendimos a travez de la experimentacion, como lograr la optimizacion de sus hiperparÃ¡metros.

## ğŸ–¥ï¸WORKFLOW con LIGHT GBMğŸ–¥ï¸: 
A partir de un workflow que utiliza light GBM como modelo predictivo tuvimos que observar todas las etapas del mismo, formamos grupos, elegimos una etapa y tuvimos que realizar un experimento. 

## ğŸŒˆExperimento 5 variables FE con Random ForestğŸŒˆ:
**Objetivos**: 
- Comprobar si la aplicacion de variables, al algoritmo de lightGBM, con el metodo de random forest aumenta las ganancias.
- Comprobar si las variables generadas por el metodo de random forest se encuentran entre las primeras 10 variables mas importantes del algoritmo.

**Links**:
- [Diapositivas con presentacion](https://docs.google.com/presentation/d/1KIcsk7HJptT2XRZ5IJFBqVCB7M-uPmEA/edit?usp=drive_link&ouid=107550161041521431022&rtpof=true&sd=true)
- [Video del experimento](https://www.youtube.com/watch?v=dNkziagnSHc)

**Integrantes**:
- [Maria Constanza Florio](www.linkedin.com/in/mariaconstanzaflorio)
- [Marianela Sansone Betella](https://www.linkedin.com/in/marianela-sansone/)

## âœ”ï¸Corridas finalesâœ”ï¸:
Luego de realizar experimentos en distintos grupos, tuvimos que observar las conclusiones de nuestros compaÃ±eros en cada parte del workflow segun lo que habia elegido cada grupo. A partir de las conclusiones de nuestros compaÃ±eros, de que modificacion generaba mas ganancia, realizamos nuevas corridas para obtener cada vez mas ganancia. Tambien trabajamos en grupo y subimos resultados de cada corrida a Kaggle. 
